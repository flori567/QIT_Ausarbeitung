{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Bibliotheken einlesen\n",
    "\n",
    "Für das Aufbereiten und Visualisieren, sowie für die Erstellung der Machine Learning Modelle werden verschiedene Bibliotheken benötigt. Folgende Python Bibiliotheken werden zur Durchführung der Analysen verwendet:\n",
    "\n",
    "##### *pandas*\n",
    "\n",
    "Mit der [**pandas**](https://pandas.pydata.org/) Bibiliothek können Daten aus verschiedenen Formaten in ein Data Frame eingelesen werden. Es stehen weiterhin Funktionen für die Datenbereinigung, für das Aggregieren oder Transformieren von Daten und anderen Dingen zur Verfügung.\n",
    "\n",
    "---\n",
    "\n",
    "##### matplotlib\n",
    "\n",
    "[**matplotlib**](https://matplotlib.org/) ist eine weit verbreitete Python Bibliothek mit der man verschiedene Charts erstellen kann. Sie bietet viele Konfigurationsmöglichkeiten, um auch komplexe Darstellungen zu ermöglichen\n",
    "\n",
    "---\n",
    "\n",
    "##### *seaborn*\n",
    "\n",
    "Die [**seaborn**](https://seaborn.pydata.org/) Bibliothek baut auf der Library matplotlib auf und ermöglicht es, mit einfacher Syntax anschauliche Datenvisualisierungen zu erzeugen. Im Vergleich zu matplotlib wirken die Grafiken moderner und sind mit weniger Kommandos zu erstellen.\n",
    "\n",
    "---\n",
    "\n",
    "##### *plotly*\n",
    "\n",
    "Die [**plotly**](https://plotly.com/) .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# For ML models\n",
    "from sklearn.linear_model import LinearRegression ,LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC ,SVR\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Überblick über die Daten erhalten\n",
    "\n",
    "Im nächsten Schritt wird sich ein Überblick über die Daten verschafft. Dabei werden die einzelnen Variablen betrachtet und beschrieben.\n",
    "\n",
    "Dazu werden die Daten aus der CSV-Datei *train.csv* in ein pandas DataFrame *df* eingelesen. Anschließend wird mit dem Aufruf des DataFrame-Namen eine Übersicht des Datasets ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('heart_2020_cleaned.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Aus der Übersicht geht hervor, dass der Datensatz aus insgesamt 319795 Zeilen und 18 Spalten besteht. Sowohl die Anzahl Zeilen also auch die Anzahl der Spalten eignet sich sehr gut für die Entwicklung eines aussagekräftigen Modells. Für ein besseres Verständnis des Datasets werden im folgenden die Beschreibungen der Spalten aufgeführt:\n",
    "\n",
    "| Variable      | Beschreibung |\n",
    "| :-----------   | :-----------  |\n",
    "| **HeartDisease**  | **Zielvariable**. Befragte, die jemals eine koronare Herzkrankheit (KHK) oder einen Myokardinfarkt (MI) hatten   |\n",
    "| BMI     | Body Mass Index (BMI)         |\n",
    "| Smoking | Haben die Probanden in ihrem Leben mehr als 100 Zigaretten geraucht? |\n",
    "| AlcoholDrinking | Starke Trinker (erwachsene Männer mit mehr als 14 Getränken pro Woche und erwachsene Frauen mit mehr als 7 Getränken pro Woche) |\n",
    "| Stroke | Wurde dem Probanden jemals gesagt, dass er einen Schlaganfall hatte? |\n",
    "| PhysicalHealth | An wie viele der letzten 30 Tage hatten die Probanden physische körperliche Beschwerden |\n",
    "| MentalHealth | An wie viele der letzten 30 Tage hatten die Probanden psychische Beschwerden |\n",
    "| DiffWalking | Haben die Probanden starke Beschwerden, Treppen zu steigen? |\n",
    "| Sex | Geschlecht der Probanden |\n",
    "| AgeCategory | Alterskategorie (insgesamt 14 Kategorien) |\n",
    "| Race | Rasse / Ethnizität |\n",
    "| Diabetic | Hatte der Proband jemals Diabetes? |\n",
    "| PhysicalActivity | Hat der Proband in den letzten 30 Tagen Sport gemacht |\n",
    "| GenHealth | Wie schätzt der Proband seine Gesundheite ein -> Exzellent / Sehr gut / gut / angemessen / schlecht |\n",
    "| SleepTime | Durschnittliche Schlafzeit in Stunden |\n",
    "| Asthma | Hatte der Proband jemals Asthma? |\n",
    "| KidneyDisease | Wurde dem Probanden jemals gesagt, dass Sie eine Nierenerkrankung haben, ausgenommen Nierensteine, Blasenentzündung oder Inkontinenz? |\n",
    "| SkinCancer | Hatte der Proband jemals Hautkrebs? |\n",
    "\n",
    "\n",
    "Anhand der Daten der verschiedenen Spalten ist zu erkennen, dass das Dataset sowohl kategorische, als auch kontinuierliche Spalten besitzt. Für die unterschiedlichen Spaltentypen sind unterschiedliche Analysen und Visualisierungen sinnvoll. Daher wird im Folgenden eine **Aufteilung der Spalten in Arrays** vorgenommen, um sie im Anschluss getrennt analysieren zu können.\n",
    "\n",
    "Das Array *cat_cols* hält alle kategorischen Spalten, das Array *con_cols* alle kontinuierlichen Spalten.\n",
    "Zusätzlich wird ein Array angelegt mit der Zielvariable *price_range*. Diese wird später für die Vorhersage des Preises eines Smartphones genutzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## AgeCategory zu einer kontinuierlichen Variable konvertieren\n",
    "\n",
    "encode_AgeCategory = {'55-59':57, '80 or older':80, '65-69':67, '75-79':77,'40-44':42,'70-74':72,'60-64':62, '50-54':52,'45-49':47,'18-24':21,'35-39':37, '30-34':32,'25-29':27}\n",
    "df['AgeCategory'] = df['AgeCategory'].apply(lambda x: encode_AgeCategory[x])\n",
    "df['AgeCategory'] = df['AgeCategory'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cat_cols = ['Smoking','AlcoholDrinking','Stroke','DiffWalking','Sex','Race',\n",
    "            'Diabetic', 'PhysicalActivity', 'GenHealth', 'Asthma', 'KidneyDisease', 'SkinCancer']\n",
    "\n",
    "con_cols = [\"BMI\",\"PhysicalHealth\",\"MentalHealth\",\"AgeCategory\", \"SleepTime\"]\n",
    "\n",
    "target_col = [\"HeartDisease\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Bevor die einzelnen Spalten analysiert werden, werden zunächst noch einige Analysen über den Datensatz insgesamt vorgenommen. So werden beispielsweise die eindeutigen Werte pro Spalte betrachtet, oder ob Spalten vorliegen, die null-Werte enthalten.\n",
    "\n",
    "Ziel ist es, die Qualtät des Datensatzes zu ermitteln. Fehlende oder fälschliche Daten können im Verlauf der Analyse oder auch bei der Erstellung der Modelle zu schlechten oder falschen Ergebnissen führen.\n",
    "\n",
    "Hierzu wird eine Übersicht als Tabelle erstellt, in der der Datentyp, die fehlenden und eindeutigen Werte, sowie das Minimum und Maximum pro Spalte dargestellt wird. Zur Erstellung dieser Werte bietet die Bibliothek *pandas* einige hilfreiche Funktionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Datentyp\n",
    "data_types = pd.DataFrame(\n",
    "    df.dtypes,\n",
    "    columns=['Datentyp']\n",
    ")\n",
    "\n",
    "## Fehlende Werte\n",
    "missing_data = pd.DataFrame(\n",
    "    df.isnull().sum(),\n",
    "    columns=['Fehlende Werte']\n",
    ")\n",
    "\n",
    "## Eindeutige Werte\n",
    "unique_values = pd.DataFrame(\n",
    "    columns=['Eindeutige Werte']\n",
    ")\n",
    "for row in list(df.columns.values):\n",
    "    unique_values.loc[row] = [df[row].nunique()]\n",
    "\n",
    "## Minimum\n",
    "minimum_values = pd.DataFrame(\n",
    "    columns=['Minimaler Wert']\n",
    ")\n",
    "for row in list(df.columns.values):\n",
    "    minimum_values.loc[row] = [df[row].min()]\n",
    "\n",
    "## Maximum\n",
    "maximum_values = pd.DataFrame(\n",
    "    columns=['Maximaler Wert']\n",
    ")\n",
    "for row in list(df.columns.values):\n",
    "    maximum_values.loc[row] = [df[row].max()]\n",
    "\n",
    "\n",
    "dq_report = data_types.join(missing_data).join(unique_values).join(minimum_values).join(maximum_values)\n",
    "dq_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Folgende **Erkenntnisse** gehen aus der oberen Übersicht hervor:\n",
    "\n",
    "1. Nahezu alle Spalten besitzen den Datentyp int64. Lediglich die Spalten clock_speed und m_dep sind float64-Spalten. Das gesamte Dataset besteht demnach aus Zahlen. Es gibt also keine Text-Spalten oder ähnliches.\n",
    "\n",
    "2. Keine der Spalten weißt fehlende Werte auf. Im Dataset liegen demnach keine Einträge mit null-Werte vor.\n",
    "\n",
    "3. Es gibt Spalten im Dataset mit lediglich 2 eindeutigen Werte. Dies deutet auf Boolean-Spalten hin. Darüber hinaus gibt es Spalten mit nur wenigen Ausprägungen, die vermutlich kategorische Werte abbilden. Zuletzt gibt es Spalten mit sehr viele eindeutigen Werten, die auf kontinuierliche Werte hindeuten.\n",
    "\n",
    "4. Die Minium und Maximum Werte der Spalten geben den Wertebereich an.\n",
    "\n",
    "##### Bewertung\n",
    "\n",
    "Insgesamt weißt das Dataset eine sehr gute Qualität auf. Es liegen keine fehlenden Werte vor, die das Ergebnis der Vorhersage oder der Analysen beeinträchtigen könnten. Darüber hinaus können im Dataset ausschließlich mit Zahlen gearbeitet werden. Es muss also keine Konvertierung von Textspalten oder ähnliches vorgenommen werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Unvariate Analyse der Spalten\n",
    "\n",
    "Nachdem eine Überblick über das Dataset gegeben wurde, werden nun Spalten des Dataset einzeln betrachtet und statistische Auswertungen erstellt. Diesen Vorgang nennt man auch \"Unvariate Analyse\". Es werden also noch keine Spalten in Beziehung gesetzt.\n",
    "Zu Analyse werden die kategorischen und kontinuierlichen Spalten gesondert betrachtet, wie bereits eingangs erwähnt. Es bieten sich pro Spaltentyp unterschiedliche Visualisierungen und Analysen an.\n",
    "\n",
    "Zunächst werden die **kategorischen Spalten** mithilfe von Bar-Charts betrachtet. Hierzu werden alle kategorischen Spalten in einer gemeinsamen Übersicht mithilfe von Subploty der Plotly-Bibliothek dargestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=3, cols=4, subplot_titles=(\"Smoking\", \"AlcoholDrinking\", \"Stroke\", \"DiffWalking\", \"Sex\", \"AgeCategory\",\n",
    "                                                    \"Race\", \"Diabetic\", \"PhysicalActivity\", \"GenHealth\", \"Asthma\",\n",
    "                                                    \"KidneyDisease\", \"SkinCancer\"))\n",
    "\n",
    "\n",
    "fig.add_trace(go.Histogram(histfunc=\"count\",  x=df['Smoking']),\n",
    "              row=1, col=1)\n",
    "fig.add_trace(go.Histogram(histfunc=\"count\",  x=df['AlcoholDrinking']),\n",
    "              row=1, col=2)\n",
    "fig.add_trace(go.Histogram(histfunc=\"count\",  x=df['Stroke']),\n",
    "              row=1, col=3)\n",
    "fig.add_trace(go.Histogram(histfunc=\"count\",  x=df['DiffWalking']),\n",
    "              row=1, col=4)\n",
    "fig.add_trace(go.Histogram(histfunc=\"count\",  x=df['Sex']),\n",
    "              row=2, col=1)\n",
    "fig.add_trace(go.Histogram(histfunc=\"count\",  x=df['Race']),\n",
    "              row=2, col=2)\n",
    "fig.add_trace(go.Histogram(histfunc=\"count\",  x=df['Diabetic']),\n",
    "              row=2, col=3)\n",
    "fig.add_trace(go.Histogram(histfunc=\"count\",  x=df['PhysicalActivity']),\n",
    "              row=2, col=4)\n",
    "fig.add_trace(go.Histogram(histfunc=\"count\",  x=df['GenHealth']),\n",
    "              row=3, col=1)\n",
    "fig.add_trace(go.Histogram(histfunc=\"count\",  x=df['Asthma']),\n",
    "              row=3, col=2)\n",
    "fig.add_trace(go.Histogram(histfunc=\"count\",  x=df['KidneyDisease']),\n",
    "              row=3, col=3)\n",
    "fig.add_trace(go.Histogram(histfunc=\"count\",  x=df['SkinCancer']),\n",
    "              row=3, col=4)\n",
    "\n",
    "fig.update_layout(height=700, title_text=\"Kategorische Variablen\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Für die Betrachtung der kontinuierlichen Variablen bieten sich sowohl Histogramme und auch Boxplots an. Boxplots sind Diagramme, die zur graphischen Darstellung der Verteilung von mindestens ordinalskalierten Merkmalen verwendet werden. Es fasst dabei verschiedene Streuungs- und Lagemaße in einer Darstellung zusammen. Ein Box-Plot soll schnell einen Eindruck darüber vermitteln, in welchem Bereich die Daten liegen und wie sie sich über diesen Bereich verteilen.\n",
    "\n",
    "Ein Boxplot fasst folgende Werte in einer Darstellung zusammen:\n",
    "- Minimum\n",
    "- Unteres Quartil\n",
    "- Median\n",
    "- Oberes Quartil\n",
    "- Maximum\n",
    "- Spannweite\n",
    "- Interquartilsabstand (IQR)\n",
    "\n",
    "Darüber hinaus werden extreme Ausreißer (3x IQR) in den Daten als Punkte dargestellt.\n",
    "\n",
    "Ein Histogramm liefert darüber hinaus die grafische Darstellung der absoluten oder relativen Häufigkeitsverteilung eines quantitativen, klassierten Merkmals in einem speziellen Säulendiagramm: Der Flächeninhalt der einzelnen (aneinandergrenzenden) Säulen gibt die Häufigkeit der jeweiligen Klassen wider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## BMI\n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(histfunc=\"count\",  x=df['BMI']),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Box(y=df['BMI']),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(height=400, width=950, title_text=\"Body Mass Index\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BMI\n",
    "sns.set(rc={'figure.figsize':(26,9.27)})\n",
    "\n",
    "plt.subplot(231)\n",
    "sns.boxplot(data=df, x=\"BMI\")\n",
    "plt.subplot(232)\n",
    "sns.histplot(data=df, x=\"BMI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## PhysicalHealth\n",
    "\n",
    "plt.subplot(231)\n",
    "sns.boxplot(data=df, x=\"PhysicalHealth\")\n",
    "plt.subplot(232)\n",
    "sns.countplot(x=df[\"PhysicalHealth\"].astype(int), color='#5975a4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## MentalHealth\n",
    "\n",
    "plt.subplot(231)\n",
    "sns.boxplot(data=df, x=\"MentalHealth\")\n",
    "plt.subplot(232)\n",
    "sns.countplot(x=df[\"MentalHealth\"].astype(int), color='#5975a4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## AgeCategory\n",
    "\n",
    "plt.subplot(231)\n",
    "sns.boxplot(data=df, x=\"AgeCategory\")\n",
    "plt.subplot(232)\n",
    "sns.countplot(x=df[\"AgeCategory\"].astype(int), color='#5975a4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SleepTime\n",
    "\n",
    "plt.subplot(231)\n",
    "sns.boxplot(data=df, x=\"SleepTime\")\n",
    "plt.subplot(232)\n",
    "sns.countplot(x=df[\"SleepTime\"].astype(int), color='#5975a4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Bivariate Analyse der Spalten\n",
    "\n",
    "Im Anschluss an die unvariate Analyse folgt die bivariate Analyse der Spalten. Der Fokus liegt hier in der Suche nach Beziehungen zwischen 2 oder mehr Spalten. Genauer gesagt ist das Ziel, eine Beziehung zischen der Zielvariabel *HeartDisease* und einer beschreibenden Variable wie z.B. *Smoking* zu finden. Es wird also eine Art empirische Beziehung zwischen den Variablen ermittelt.\n",
    "\n",
    "Außerdem werden Korrelationen zwischen den beschreibenden Variablen ermittelt. Eine hohe Korrelation zweier Variablen sagt aus, dass die eine Variable die andere bedingt.\n",
    "\n",
    "Vor der bivariaten Analyse werden allerdings noch Hypothesen aufgestellt, die eine Richtung bei der Analyse der Daten vorgeben. Man stellt also Vermutungen zu den Daten auf, die im Anschluss mittels Analysen und Visualisierung belegt oder wiederlegt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Hypthesen**:\n",
    "\n",
    "1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(16, 9.27)})\n",
    "\n",
    "plt.subplot(231)\n",
    "sns.countplot(x=\"Smoking\", hue='HeartDisease', data=df)\n",
    "plt.subplot(232)\n",
    "sns.countplot(x=\"AlcoholDrinking\", hue='HeartDisease', data=df)\n",
    "plt.subplot(233)\n",
    "sns.countplot(x=\"Stroke\", hue='HeartDisease', data=df)\n",
    "\n",
    "variables = [\"Smoking\", \"AlcoholDrinking\", \"Stroke\"]\n",
    "\n",
    "for v in variables:\n",
    "    smoke_and_heart_disease = len(df[(df['HeartDisease']=='Yes') & (df[v]=='Yes')])\n",
    "    num_smoke = len(df[df[v]=='Yes'])\n",
    "    no_smoke_and_heart_disease = len(df[(df['HeartDisease']=='Yes') & (df[v]=='No')])\n",
    "    num_no_smoke = len(df[df[v]=='No'])\n",
    "    print('Wahrscheinlichkeit für einen Herzinfakt, wenn die Ausprägung ' + v + ' \"Yes\" ist', \n",
    "          smoke_and_heart_disease/num_smoke)\n",
    "    print('Wahrscheinlichkeit für einen Herzinfakt, wenn die Ausprägung ' + v + ' \"No\" ist', \n",
    "          no_smoke_and_heart_disease/num_no_smoke)\n",
    "    print('-------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplot(234)\n",
    "sns.countplot(x=\"DiffWalking\", hue='HeartDisease', data=df)\n",
    "plt.subplot(235)\n",
    "sns.countplot(x=\"Sex\", hue='HeartDisease', data=df)\n",
    "plt.subplot(236)\n",
    "sns.countplot(x=\"Race\", hue='HeartDisease', data=df)\n",
    "\n",
    "variables = [\"DiffWalking\", \"Sex\"]\n",
    "\n",
    "'''\n",
    "for v in variables:\n",
    "    smoke_and_heart_disease = len(df[(df['HeartDisease']=='Yes') & (df[v]=='Yes')])\n",
    "    num_smoke = len(df[df[v]=='Yes'])\n",
    "    no_smoke_and_heart_disease = len(df[(df['HeartDisease']=='Yes') & (df[v]=='No')])\n",
    "    num_no_smoke = len(df[df[v]=='No'])\n",
    "    print('Wahrscheinlichkeit für einen Herzinfakt, wenn die Ausprägung ' + v + ' \"Yes\" ist', \n",
    "          smoke_and_heart_disease/num_smoke)\n",
    "    print('Wahrscheinlichkeit für einen Herzinfakt, wenn die Ausprägung ' + v + ' \"No\" ist', \n",
    "          no_smoke_and_heart_disease/num_no_smoke)\n",
    "    print('-------------')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplot(234)\n",
    "sns.countplot(x=\"Diabetic\", hue='HeartDisease', data=df)\n",
    "plt.subplot(235)\n",
    "sns.countplot(x=\"PhysicalActivity\", hue='HeartDisease', data=df)\n",
    "plt.subplot(236)\n",
    "sns.countplot(x=\"GenHealth\", hue='HeartDisease', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.subplot(234)\n",
    "sns.countplot(x=\"Asthma\", hue='HeartDisease', data=df)\n",
    "plt.subplot(235)\n",
    "sns.countplot(x=\"KidneyDisease\", hue='HeartDisease', data=df)\n",
    "plt.subplot(236)\n",
    "sns.countplot(x=\"SkinCancer\", hue='HeartDisease', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zielvariable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(16, 5.27)})\n",
    "sns.countplot(x=\"HeartDisease\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Korrelationsmatrix aller Variablen erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df[con_cols].corr().transpose()\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "gs = fig.add_gridspec(1,1)\n",
    "gs.update(wspace=0.3, hspace=0.15)\n",
    "ax0 = fig.add_subplot(gs[0,0])\n",
    "\n",
    "color_palette = [\"#5833ff\",\"#da8829\"]\n",
    "mask = np.triu(np.ones_like(df_corr))\n",
    "ax0.text(1.5,-0.1,\"Correlation Matrix\",fontsize=22, fontweight='bold', fontfamily='serif', color=\"#000000\")\n",
    "df_corr = df[con_cols].corr().transpose()\n",
    "sns.heatmap(df_corr,mask=mask,fmt=\".1f\",annot=True,cmap='YlGnBu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = df.corr().round(2)\n",
    "sns.heatmap(correlation,annot=True ,cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Modell erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Standardisierung der kontinuierlichen Variablen\n",
    "\n",
    "Scaler = StandardScaler()\n",
    "df[con_cols] = Scaler.fit_transform(df[con_cols])\n",
    "\n",
    "df[con_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer encode columns with 2 unique values\n",
    "for col in ['HeartDisease', 'Smoking', 'AlcoholDrinking', 'Stroke', 'DiffWalking', 'Sex', 'PhysicalActivity', 'Asthma', 'KidneyDisease', 'SkinCancer']:\n",
    "    if df[col].dtype == 'O':\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# One-hot encode columns with more than 2 unique values\n",
    "df = pd.get_dummies(df, columns=['Race', 'Diabetic', 'GenHealth', ], prefix = ['Race', 'Diabetic', 'GenHealth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split dataset for training and testing\n",
    "\n",
    "#Select Features\n",
    "features = df.drop(columns =['HeartDisease'], axis = 1)\n",
    "\n",
    "#Select Target \n",
    "target = df['HeartDisease']\n",
    "\n",
    "# Set Training and Testing Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, shuffle = True, test_size = .2, random_state = 44)\n",
    "\n",
    "\n",
    "print('Shape of training feature:', X_train.shape)\n",
    "print('Shape of testing feature:', X_test.shape)\n",
    "print('Shape of training label:', y_train.shape)\n",
    "print('Shape of training label:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test, y_test):\n",
    "    from sklearn import metrics\n",
    "\n",
    "    # Predict Test Data \n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Calculate accuracy, precision, recall, f1-score, and kappa score\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    prec = metrics.precision_score(y_test, y_pred)\n",
    "    rec = metrics.recall_score(y_test, y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred)\n",
    "    kappa = metrics.cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "    # Calculate area under curve (AUC)\n",
    "    y_pred_proba = model.predict_proba(x_test)[::,1]\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    # Display confussion matrix\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    return {'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1, 'kappa': kappa, \n",
    "            'fpr': fpr, 'tpr': tpr, 'auc': auc, 'cm': cm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a model using KNeighborsClassifier \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Evaluate Model\n",
    "knn_eval = evaluate_model(knn, X_test, y_test)\n",
    "\n",
    "# Print result\n",
    "print('Accuracy:', knn_eval['acc'])\n",
    "print('Precision:', knn_eval['prec'])\n",
    "print('Recall:', knn_eval['rec'])\n",
    "print('F1 Score:', knn_eval['f1'])\n",
    "print('Cohens Kappa Score:', knn_eval['kappa'])\n",
    "print('Area Under Curve:', knn_eval['auc'])\n",
    "print('Confusion Matrix:\\n', knn_eval['cm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "# Building Decision Tree model \n",
    "# https://scikit-learn.org/stable/modules/tree.html\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 3, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate Model\n",
    "clf_eval = evaluate_model(clf, X_test, y_test)\n",
    "\n",
    "# Print result\n",
    "print('Accuracy:', clf_eval['acc'])\n",
    "print('Precision:', clf_eval['prec'])\n",
    "print('Recall:', clf_eval['rec'])\n",
    "print('F1 Score:', clf_eval['f1'])\n",
    "print('Cohens Kappa Score:', clf_eval['kappa'])\n",
    "print('Area Under Curve:', clf_eval['auc'])\n",
    "print('Confusion Matrix:\\n', clf_eval['cm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "tree.plot_tree(clf,\n",
    "               feature_names = df.columns,\n",
    "               class_names = target.astype(str),\n",
    "               filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Decision Tree model \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate Model\n",
    "rfc_eval = evaluate_model(rfc, X_test, y_test)\n",
    "\n",
    "# Print result\n",
    "print('Accuracy:', rfc_eval['acc'])\n",
    "print('Precision:', rfc_eval['prec'])\n",
    "print('Recall:', rfc_eval['rec'])\n",
    "print('F1 Score:', rfc_eval['f1'])\n",
    "print('Cohens Kappa Score:', rfc_eval['kappa'])\n",
    "print('Area Under Curve:', rfc_eval['auc'])\n",
    "print('Confusion Matrix:\\n', rfc_eval['cm'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract single tree\n",
    "estimator = rfc.estimators_[5]\n",
    "\n",
    "from sklearn import tree\n",
    "tree.plot_tree(rfc.estimators_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating the object and fitting\n",
    "# https://scikit-learn.org/stable/modules/svm.html\n",
    "\n",
    "svc = SVC(kernel='linear', C=1, random_state=42).fit(X_train,y_train)\n",
    "\n",
    "# predicting the values\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# printing the test accuracy\n",
    "print(\"The test accuracy score of SVM is \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "import keras\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import warnings\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(11, kernel_initializer='uniform', activation = 'relu', input_shape=(X_train.shape[1],)))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(11, kernel_initializer='uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(1, kernel_initializer='uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "opt = tensorflow.keras.optimizers.Adam(learning_rate=0.01)\n",
    "classifier.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train, validation_data=(X_test, y_test), epochs = 10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred.round())\n",
    "sns.heatmap(cm,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False)\n",
    "#accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "ac=accuracy_score(y_test, y_pred.round())\n",
    "print('accuracy of the model: ',ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
